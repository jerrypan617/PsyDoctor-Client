# 心理医生聊天后端

本后端作为代理，将请求转发到云服务器上的模型服务，并集成了**RAG（检索增强生成）**功能来优化长对话的记忆管理。

## 功能特性

### RAG记忆管理
- **语义检索**：使用向量相似度检索与当前消息相关的历史对话
- **时间衰减**：最近的消息权重更高，确保上下文相关性
- **智能上下文构建**：自动组合系统提示、相关历史、最近对话和当前消息
- **持久化存储**：对话记忆保存在本地JSON文件中

## 服务器配置

在 `main.py` 中配置云服务器地址：

```python
SERVER_URL = "http://129.211.164.244:8000"
```

## 安装依赖

```bash
pip install -r requirements.txt
```

**注意**：首次安装时，`sentence-transformers` 会自动下载embedding模型（约420MB），这可能需要一些时间。

## 运行服务

```bash
python main.py
```

或使用 uvicorn:

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

服务将在 http://localhost:8000 启动

## 接口说明

### POST /chat

接收聊天请求，使用RAG检索相关历史并转发到云服务器。

**请求体**:
```json
{
  "message": "用户消息",
  "conversation_history": [
    {"role": "user", "content": "历史消息1"},
    {"role": "assistant", "content": "历史回复1"}
  ],
  "temperature": 0.7,
  "conversation_id": "可选对话ID"
}
```

**返回**:
```json
{
  "response": "模型回复",
  "conversation_id": "对话ID"
}
```

## RAG工作原理

1. **向量化**：使用多语言embedding模型将对话消息转换为向量
2. **检索**：基于当前消息的语义相似度检索相关历史消息
3. **时间衰减**：最近24小时的消息权重1.0，7天内0.8，30天内0.5，更早0.3
4. **上下文组装**：
   - 系统提示
   - 检索到的相关历史（最多3条）
   - 最近15条历史消息（8个对话来回，共16条消息包括当前消息）
   - 当前用户消息

## 配置参数

在 `memory_manager.py` 中可以调整以下参数：

- `max_recent_messages`: 保留的最近消息数量（默认16，即8个对话来回）
- `retrieval_top_k`: 检索返回的最相关消息数量（默认10）
- `similarity_threshold`: 相似度阈值（默认0.3）

**注意**：滑动窗口确保最后一条历史消息是assistant，当前消息是user，保证完整的对话格式。

## 记忆存储

对话记忆保存在 `conversation_memory.json` 文件中，包含：
- 消息内容
- 元数据（创建时间、更新时间等）
- 向量在运行时计算（不持久化）

## 注意事项

1. **首次运行**：需要下载embedding模型，可能需要几分钟
2. **内存使用**：向量计算会占用一定内存，建议至少2GB可用内存
3. **性能**：检索过程需要计算向量相似度，可能会有轻微延迟（通常<100ms）
